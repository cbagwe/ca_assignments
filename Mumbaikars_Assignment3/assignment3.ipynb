{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1495f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from better_profanity import profanity\n",
    "from nltk.stem import PorterStemmer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48d3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataset \n",
    "with open(\"train-data-prepared.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "# get training dataset \n",
    "with open(\"val-data-prepared.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "# get testing dataset \n",
    "with open(\"val-data-prepared.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca5dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create spacy object\n",
    "nlp_english = spacy.load(\"en_core_web_sm\")\n",
    "#create Stemmer object\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ae5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_ids', 'train_posts', 'train_label', 'val_ids', 'val_posts', 'val_label', 'test_ids', 'test_posts', 'test_label'])\n"
     ]
    }
   ],
   "source": [
    "entire_dataset = {\n",
    "    'train_ids': [thread[\"id\"] for thread in train_data],\n",
    "    'train_posts': [thread[\"preceding_posts\"] for thread in train_data],\n",
    "    'train_label': [thread[\"label\"] for thread in train_data],\n",
    "    \n",
    "    'val_ids': [thread[\"id\"] for thread in val_data],\n",
    "    'val_posts': [thread[\"preceding_posts\"] for thread in val_data],\n",
    "    'val_label': [thread[\"label\"] for thread in val_data],\n",
    "    \n",
    "    'test_ids': [thread[\"id\"] for thread in test_data],\n",
    "    'test_posts': [thread[\"preceding_posts\"] for thread in test_data],\n",
    "    'test_label': [thread[\"label\"] for thread in test_data],\n",
    "}\n",
    "\n",
    "print(entire_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f8a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for thread in val_data:\n",
    "#    authors = []\n",
    "#    for comment in thread[\"preceding_posts\"]:\n",
    "#        if comment[\"author_name\"] not in authors:\n",
    "#            authors.append(comment[\"author_name\"])\n",
    "#    \n",
    "#    if len(authors) >= 2:\n",
    "#        print(thread[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85d4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ass', 'idiot', 'fuck', 'shit', 'racist']\n",
      "['becaus', 'it', ' s', 'illeg', 'in', 'our', 'realiti', 'vs ', 'the', 'propos', 'realiti', 'that', 'me', 'op', 'and', 'everyon', 'els', 'on', 'thi', 'thread', 'are', 'comment', 'about', 'keep', 'up', 'qwert']\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation, space, urls from text\n",
    "def clean_text(text):\n",
    "    parsed_text = nlp_english(text)\n",
    "    clean_text = []\n",
    "    for token in parsed_text:\n",
    "        stop_flag = (token.is_punct or token.is_space or  \n",
    "                 token.like_url)\n",
    "        if (not stop_flag):\n",
    "            clean_text.append(re.sub('[^A-Za-z0-9]+', ' ',token.text.lower()))\n",
    "            \n",
    "    return clean_text\n",
    "\n",
    "def stem_text(text):\n",
    "    return [stemmer.stem(word) for word in clean_text(text)]\n",
    "\n",
    "print(stem_text(\"ass idiot fuck shit racist \"))\n",
    "print(stem_text(\"...because it's illegal in our reality, vs. the proposed reality that me, OP, and everyone else on this thread are commenting about.\\n\\nKeep up, qwert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baff7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if the OP has addressed the other person in some way\n",
    "def count_insults(text):\n",
    "    insult_words = [\"ass\", \"idiot\", \"fuck\", \"shit\"]\n",
    "    counter = 0\n",
    "    for word in text:\n",
    "        if word in insult_words:\n",
    "            counter = counter + 1\n",
    "            \n",
    "    return counter\n",
    "        \n",
    "#print(check_insults(clean_text(\"> a) right, because women are non-sexual creatures who would never use prostitutes themselves\\n\\ni think you vastly overestimate the number of women that pay for sex...\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f8436f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def check_author_name(text, name):\n",
    "#    flag = 0\n",
    "#    for word in text:\n",
    "#        if name in word or word in name:\n",
    "#            flag = flag + 1\n",
    "#    return flag\n",
    "\n",
    "#print(check_author_name(['becaus', 'it', ' s', 'illeg', 'in', 'our', 'realiti', 'vs ', 'the', 'propos', 'realiti', 'that', 'me', 'op', 'and', 'everyon', 'els', 'on', 'thi', 'thread', 'are', 'comment', 'about', 'keep', 'up', 'qwert'],\"qwertx0815\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8ed80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should return one feature vector for one string\n",
    "# features -> Author's turn, length of argument, insults, sentiment\n",
    "def gather_data(thread):\n",
    "    returnObj = {}\n",
    "    for i in range(len(thread[\"preceding_posts\"])):\n",
    "        comment_data = {}\n",
    "        comment = thread[\"preceding_posts\"][i]\n",
    "        # clean text\n",
    "        comment_data[\"text\"] = stem_text(comment[\"body\"])\n",
    "        # Length just in case of Godwin's Law\n",
    "        comment_data[\"char_length_vec\"] = [len(\"\".join(comment_data[\"text\"]))]\n",
    "        # refer's to other user/author\n",
    "        #comment_data[\"refer_author\"] = [check_author_name(comment_data[\"text\"], thread[\"preceding_posts\"][1-i][\"author_name\"])]\n",
    "        # check for some common insults\n",
    "        comment_data[\"insults_vec\"] = [count_insults(comment_data[\"text\"])]\n",
    "        # get sentiment\n",
    "        sentiment = TextBlob(' '.join(comment_data[\"text\"])).sentiment\n",
    "        comment_data[\"sentiment\"] =  [sentiment.polarity, sentiment.subjectivity]\n",
    "        feature_vec = comment_data[\"char_length_vec\"] + comment_data[\"insults_vec\"] + comment_data[\"sentiment\"]\n",
    "        \n",
    "        returnObj[\" \".join(comment_data[\"text\"])] = feature_vec\n",
    "        \n",
    "    return returnObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7204dd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'becaus it  s illeg in our realiti vs  the propos realiti that me op and everyon els on thi thread are comment about keep up qwert': [104, 0, 0.0, 0.0], 'i live in a nation were it is complet legal to pay for sex surround by other nation where it is also mostli legal guess what no woman pay for sex and you  ll notic that it be illeg in the us doe n t stop men from go to prostitut keep up bunchanumb edit for context it  s a first world nation with consider more liber attitud regard sex then the us': [276, 0, 0.19356060606060607, 0.3513888888888889]}\n",
      "\n",
      "{'becaus make prostitut legal make it veri much more difficult to polic thi as ha been found repeatedli in countri around the world the women who are brought into the countri ca n t be question becaus there is no legal justif to do so as the job they are do are legal thi is what  s been found everywher from nevada to germani to australia': [273, 0, 0.059999999999999984, 0.42000000000000004], 'i  d be interest in read up on thi do you have a sourc that exemplifi what you are refer to and also ca n t the cop question you or ask to see your immigr statu even without a warrant if voluntari': [155, 0, 0.0, 0.0]}\n",
      "\n",
      "{'whi are you link wikipedia and not direct text whi are none of your origin claim back up in case you  d actual like to read the text and not just snippet here  s the actual federalist paper which you claim to have read litterslli read thi paper 0 of your assert are back up': [219, 0, -0.01, 0.12], 'i put the wiki becaus i figur you may want a synopsi and i wa right do do it becaus perhap your read comprehens is bad sinc it wa written back in the day what do you think hamilton wa say there   the immedi elect should be made by men most capabl of analyz the qualiti adapt to the station and act under circumst favor to deliber and to a judici combin of all the reason and induc which were proper to govern their choic a small number of person select by their fellow citizen from the gener mass will be most like to possess the inform and discern requisit to such complic investig who do you think he  s talk about here rural farmer   the process of elect afford a moral certainti that the offic of presid will never fall to the lot of ani man who is not in an emin degre endow with the requisit qualif talent for low intrigu and the littl art of popular may alon suffic to elev a man to the first honor in a singl state but it will requir other talent and a differ kind of merit to establish him in the esteem and confid of the whole union or of so consider a portion of it as would be necessari to make him a success candid for the distinguish offic of presid of the unit state here he  s basic say by thi process we can weed out idiot who can win a popular contest with the mass in a state  but not the presid he did n t forese cabl news and social media unfortun honestli if you read it what do you think the messag wa': [1136, 1, 0.19976190476190475, 0.4620952380952382]}\n",
      "\n",
      "{'  real properti ha a logic absolut necess to be regist under what logic in an environ where properti ownership exist we need to know what properti belong to what person i need to know whether i  m build my hous on land that actual belong to me if i expand my properti by 10 feet that  s 10 feet less of properti belong to my neighbor so i  m not just allow to do that to report my neighbor for trespass i need to prove that properti is mine not hi line need to be drawn and those line need to be regist with the govern to enforc properti relat law you ca n t reli on that  s mine   i  m of the opinion that heller wa wrongli decid i wonder how do you approach the right protect by the 1st 4th 5th and other amend do you take an expans individualist approach if so whi do you singl out the 2nd for a restrict collect approach rememb grammat speak the present participl about militia doe not restrict the mean of the independ claus grammat the right state is pre exist and uncondit a well school elector be necessari to the secur of a free state the right of the peopl to keep and read book shall not be infring is an equival sentenc in grammar and mean would you interpret thi to mean that we can onli have and read book when act collect in our capac as the elector   mani area have registr and court have not seen anyth wrong with that would you be okay with have to regist everyth you print with the govern so they could identifi you   if a wit did n t see who someon wa in a crime but there  s a natur suspect for other reason and the wit can either confirm or disconfirm someth about the perpetr then that  s relev evid and now we just have to hope that crimin regist hi firearm rememb we can not forc him to do it nor punish him for fail to do it you find out if he ha that firearm by build enough evid for a search warrant search and find the firearm then you have one specif firearm you can attempt to match you do thi same as you would a hammer or chainsaw or ani other deadli implement': [1592, 0, -0.02610119047619048, 0.41931547619047616], '  in an environ where properti ownership exist we need to know what properti belong to what person i need to know whether i  m build my hous on land that actual belong to me if i expand my properti by 10 feet that  s 10 feet less of properti belong to my neighbor so i  m not just allow to do that to report my neighbor for trespass i need to prove that properti is mine not hi line need to be drawn and those line need to be regist with the govern to enforc properti relat law you ca n t reli on that  s mine actual a lot of societi have not had central properti registr at all some have simpli use individu document with wit for exampl and the person with the properti kept the document thi wa for exampl use by the ancient jew and a similar system wa use in some mediev area but even if that were n t the case it would n t make thi a logic necess but rather a system with it posit and neg as ani system ha and in thi case the system  s posit outweigh the neg your paragraph actual doe n t examin four of the major reason we realli have properti regist in modern societi first there  s liabil if someth happen with someon  s properti we want to know who is respons for it second there  s scale it is difficult to scale up system where peopl keep their person deed up to a larg scale with big citi and the like third there  s properti tax mani locat have properti tax and central record of real estat are necessari to administ such system fourth modern zone is veri hard to do with out such central but note that none of these reason are logic necess they are appar posit of the system which in thi case outweigh the benefit of privaci   i wonder how do you approach the right protect by the 1st 4th 5th and other amend do you take an expans individualist approach if so whi do you singl out the 2nd for a restrict collect approach the histori and intent of the amend is what matter here the militia are what becam the nation guard not privat citizen   rememb grammat speak the present participl about militia doe not restrict the mean of the independ claus grammat the right state is pre exist and uncondit   a well school elector be necessari to the secur of a free state the right of the peopl to keep and read book shall not be infring is an equival sentenc in grammar and mean would you interpret thi to mean that we can onli have and read book when act collect in our capac as the elector the problem is n t the grammar by itself but note that it doe actual say the peopl wherea the other amend do n t use that phrase and that certainli ha a collect connot but the essenti problem here is n t grammat it is that we had liter over 200 year where pretti much everyon agre what the intend mean of thi wa and it is onli in the last 40 or 50 year that anyon ha taken these expans read of the 2nd amend serious it realli may help for you to read the dissent in heller     if a wit did n t see who someon wa in a crime but there  s a natur suspect for other reason and the wit can either confirm or disconfirm someth about the perpetr then that  s relev evid and now we just have to hope that crimin regist hi firearm   rememb we can not forc him to do it nor punish him for fail to do it someth which while interest i disagre with and would in ani event under current preced onli appli to peopl who are alreadi have crimin record and again if thi realli is a problem then the logic respons to have an amend narrow or abolish the 2nd amend outright   you find out if he ha that firearm by build enough evid for a search warrant search and find the firearm then you have one specif firearm you can attempt to match you do thi same as you would a hammer or chainsaw or ani other deadli implement firearm are substanti more deadli and like to be use in crimin activ than hammer or chainsaw and one relev type of evid for get a warrant is doe he or someon he live with have a regist firearm of a relev type': [3124, 0, -0.015326253607503608, 0.33973214285714287]}\n",
      "\n",
      "{'  are you realli defend multin not be greedi thi sentenc doe n t realli make sens but i  m go to guess no not sure what point you  re tri to make and water is not a human right it is a natur resourc': [155, 0, 0.011904761904761899, 0.5082010582010582], '  thi sentenc doe n t realli make sens eli5 do you think multin can suffer from greed or are they exempt   and water is not a human right it is a natur resourc are you claim a human be that ha no money ha no right to water you do realis a person need water to surviv do you': [214, 0, 0.03571428571428571, 0.31785714285714284]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print features for some 10 tuples\n",
    "for thread in train_data[:5]:\n",
    "    print(gather_data(thread))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56d556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1936/1936 [02:02<00:00, 15.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 258/258 [00:15<00:00, 16.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 258/258 [00:15<00:00, 16.87it/s]\n"
     ]
    }
   ],
   "source": [
    "entire_dataset[\"train_prep\"] = [gather_data(thread) for thread in tqdm(train_data)]\n",
    "\n",
    "entire_dataset[\"val_prep\"] = [gather_data(thread) for thread in tqdm(val_data)]\n",
    "\n",
    "entire_dataset[\"test_prep\"] = [gather_data(thread) for thread in tqdm(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa69d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(train_bow.toarray().tolist()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f4a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_in_sentences(array, index, increasing_flag = False):\n",
    "    values = [x[index] for x in array]\n",
    "    ret_answer = values[0] < values[1]    \n",
    "    if increasing_flag:\n",
    "        return int(ret_answer)\n",
    "    else:\n",
    "        return int(not ret_answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6736e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vectors(ddict):\n",
    "    feature_vectors = list(ddict.values())\n",
    "    \n",
    "    dot_product = dot(feature_vectors[0], feature_vectors[-1])\n",
    "    norms_product = (norm(feature_vectors[0])*norm(feature_vectors[-1]))\n",
    "    if norms_product == 0:\n",
    "        cos_sim = 1\n",
    "    else:\n",
    "        cos_sim = dot_product/norms_product\n",
    "    \n",
    "    #cos_diff = 1 - cos_sim\n",
    "    avg_insults = np.average([x[1] for x in feature_vectors])\n",
    "    increasing_insults = get_delta_in_sentences(feature_vectors, 1, True)\n",
    "    avg_polarity = np.average([x[-2] for x in feature_vectors])\n",
    "    stddev_polarity = np.std([x[-2] for x in feature_vectors])\n",
    "    avg_subjectivity = np.average([x[-1] for x in feature_vectors])\n",
    "    stddev_subjectivity = np.std([x[-1] for x in feature_vectors])\n",
    "    is_decreasing_polarity = get_delta_in_sentences(feature_vectors, -2)\n",
    "    is_increasing_polarity = get_delta_in_sentences(feature_vectors, -2, True)\n",
    "    is_decreasing_subjectivity = get_delta_in_sentences(feature_vectors, -1)\n",
    "    is_increasing_subjectivity = get_delta_in_sentences(feature_vectors, -1, True)\n",
    "    #kendall_correlation, _ = kendalltau(feature_vectors[0], feature_vectors[1])\n",
    "    #print(ret_obj)\n",
    "    return [avg_insults, increasing_insults, avg_polarity, stddev_polarity, avg_subjectivity, \n",
    "        stddev_subjectivity, is_decreasing_polarity, is_increasing_polarity, \n",
    "        is_decreasing_subjectivity, is_increasing_subjectivity, cos_sim]\n",
    "    \n",
    "#combine_vectors(entire_dataset['train_prep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5142e007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA = stem_text(\"At this point it seems clear that we have very different definitions of bigotry, but I won\\'t get into that because semantics are rarely a fruitful exercise.\\n\\nYou mean you won\\'t get into it because then you would have to admit that you are defending the right of bigots to engage in prejudicial treatment of others, and that is morally indefensible.\\n\\n>It\\'s not that I think life should be fair to the \"bigot,\" it\\'s that I will resist any attempt to introduce government coercion in the free market. People should be allowed to run businesses as they please, and if those businesses are run by shitty people you can take your money elsewhere. If a business with horrible practices is able to thrive, that is more indicative of a problem with society, not just the business owner.\\n\\nThis is a disgusting attitude that glorifies those with power over those who have none.  This is the heart of fascism: power to the strong, fuck the weak.\\n\\nI sincerely hope that you are made the victim of prejudice and bigotry, so that you can one day understand how disgusting and malignant your beliefs are.\")\\nB = stem_text(\"his is a disgusting attitude that glorifies those with power over those who have none. This is the heart of fascism\\n\\nOkay, so now we\\'re getting into ad hominems. Got it. I find it interesting how I\\'m the one denouncing creeping authoritarianism and you\\'re the one calling that fascist. I\\'m not convinced you know what fascism actually means.\\n\\n>You mean you won\\'t get into it because then you would have to admit that you are defending the right of bigots to engage in prejudicial treatment of others, and that is morally indefensible.\\n\\nBigotry (noun): intolerance to those who hold different opinions from oneself.\\n\\n>I sincerely hope that you are made the victim of prejudice and bigotry, so that you can one day understand how disgusting and malignant your beliefs are.\\n\\nHmmm... Wishing ill will upon those who are different from you? Sounds a lot like how you described those bakers refusing to bake a cake for gay couples. Also seems to fit nicely into that definition of bigotry I listed above.\\n\\nBigotry comes in many forms. Thinking that anyone who isn\\'t a neo-progressive liberal such as yourself is a bigot is one of those forms. I sincerely hope you take some time to reflect on how you view others with whom you disagree, because I can\\'t see how anyone with so much animosity could possibly be happy.\\n\\nEnjoy your weekend! The weather\\'s gorgeous here, I hope it\\'s nice where you are too.\")\\n\\nprint(TextBlob(\" \".join(A)).sentiment)\\nprint(TextBlob(\" \".join(B)).sentiment)\\n\\nprint(TextBlob(\"fuck\").tags)\\nprint(TextBlob(\"should\").tags)\\nprint(TextBlob(\"are\").tags)\\nprint(TextBlob(\"idiot\").tags)\\nprint(TextBlob(\"stupid\").tags)\\nprint(TextBlob(\"can\").tags)\\nprint(TextBlob(\"you\").tags)\\nprint(TextBlob(\"your\").tags)\\nprint(TextBlob(\"you\\'re\").tags)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A = stem_text(\"At this point it seems clear that we have very different definitions of bigotry, but I won't get into that because semantics are rarely a fruitful exercise.\\n\\nYou mean you won't get into it because then you would have to admit that you are defending the right of bigots to engage in prejudicial treatment of others, and that is morally indefensible.\\n\\n>It's not that I think life should be fair to the \\\"bigot,\\\" it's that I will resist any attempt to introduce government coercion in the free market. People should be allowed to run businesses as they please, and if those businesses are run by shitty people you can take your money elsewhere. If a business with horrible practices is able to thrive, that is more indicative of a problem with society, not just the business owner.\\n\\nThis is a disgusting attitude that glorifies those with power over those who have none.  This is the heart of fascism: power to the strong, fuck the weak.\\n\\nI sincerely hope that you are made the victim of prejudice and bigotry, so that you can one day understand how disgusting and malignant your beliefs are.\")\n",
    "B = stem_text(\"his is a disgusting attitude that glorifies those with power over those who have none. This is the heart of fascism\\n\\nOkay, so now we're getting into ad hominems. Got it. I find it interesting how I'm the one denouncing creeping authoritarianism and you're the one calling that fascist. I'm not convinced you know what fascism actually means.\\n\\n>You mean you won't get into it because then you would have to admit that you are defending the right of bigots to engage in prejudicial treatment of others, and that is morally indefensible.\\n\\nBigotry (noun): intolerance to those who hold different opinions from oneself.\\n\\n>I sincerely hope that you are made the victim of prejudice and bigotry, so that you can one day understand how disgusting and malignant your beliefs are.\\n\\nHmmm... Wishing ill will upon those who are different from you? Sounds a lot like how you described those bakers refusing to bake a cake for gay couples. Also seems to fit nicely into that definition of bigotry I listed above.\\n\\nBigotry comes in many forms. Thinking that anyone who isn't a neo-progressive liberal such as yourself is a bigot is one of those forms. I sincerely hope you take some time to reflect on how you view others with whom you disagree, because I can't see how anyone with so much animosity could possibly be happy.\\n\\nEnjoy your weekend! The weather's gorgeous here, I hope it's nice where you are too.\")\n",
    "\n",
    "print(TextBlob(\" \".join(A)).sentiment)\n",
    "print(TextBlob(\" \".join(B)).sentiment)\n",
    "\n",
    "print(TextBlob(\"fuck\").tags)\n",
    "print(TextBlob(\"should\").tags)\n",
    "print(TextBlob(\"are\").tags)\n",
    "print(TextBlob(\"idiot\").tags)\n",
    "print(TextBlob(\"stupid\").tags)\n",
    "print(TextBlob(\"can\").tags)\n",
    "print(TextBlob(\"you\").tags)\n",
    "print(TextBlob(\"your\").tags)\n",
    "print(TextBlob(\"you're\").tags)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e95aef7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1936/1936 [00:00<00:00, 7520.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 258/258 [00:00<00:00, 7588.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 258/258 [00:00<00:00, 7840.96it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = [combine_vectors(thread) for thread in tqdm(entire_dataset['train_prep'])]\n",
    "x_val = [combine_vectors(thread) for thread in tqdm(entire_dataset['val_prep'])]\n",
    "x_test = [combine_vectors(thread) for thread in tqdm(entire_dataset['test_prep'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5aa02ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = entire_dataset[\"train_label\"]\n",
    "y_val = entire_dataset[\"val_label\"]\n",
    "y_test = entire_dataset[\"test_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68f2937d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5be50f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = clf.predict(x_val)\n",
    "test_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eabd521d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for val data: 0.5930232558139535\n",
      "Accuracy for test data: 0.5930232558139535\n",
      "Precision val: 0.5833333333333334\n",
      "Precision test: 0.5833333333333334\n",
      "Recall val: 0.6511627906976745\n",
      "Recall test: 0.6511627906976745\n",
      "F1 score val: 0.6153846153846155\n",
      "F1 score test: 0.6153846153846155\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for val data:\",metrics.accuracy_score(y_val, val_pred))\n",
    "print(\"Accuracy for test data:\",metrics.accuracy_score(y_test, test_pred))\n",
    "\n",
    "print(\"Precision val:\",metrics.precision_score(y_val, val_pred))\n",
    "print(\"Precision test:\",metrics.precision_score(y_test, test_pred))\n",
    "\n",
    "print(\"Recall val:\",metrics.recall_score(y_val, val_pred))\n",
    "print(\"Recall test:\",metrics.recall_score(y_test, test_pred))\n",
    "\n",
    "print(\"F1 score val:\",metrics.f1_score(y_val, val_pred))\n",
    "print(\"F1 score test:\",metrics.f1_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1233c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random classification for baseline score\n",
    "\n",
    "#random_val = {t_id: random.randint(0,1) for t_id in val_ids}\n",
    "#random_test = {t_id: random.randint(0,1) for t_id in test_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c226fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"val-random-output.json\", \"w\") as f:\n",
    "#    json.dump(random_val, f)\n",
    "# get testing dataset \n",
    "#with open(\"test-random-output.json\", \"w\") as f:\n",
    "#    json.dump(random_test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e3c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
